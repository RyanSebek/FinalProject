# FinalProject

National Esports Collegiate Conferences Case Study
Abstract: 
College esports, as a whole, is a billion-dollar industry; however, the scene is extremely fragmented. Unlike traditional sports, collegiate esports have numerous governing bodies that are all vying to be the top league. In this study, feedback form from 2021-22 and 2023-2024 year end of year reviews were analyzed using natural language processing (NLP) to identify the primary benefits that directors look for when choosing a league. After reviewing the end of year reviews provided by National Esports Collegiate Conferences (NECC), it was found that most directors loved weekly streams that featured a variety of skill levels. Directors also looked for a league that included all the core games plus a few extras all for one reasonable membership price.
Introduction:
The current state of collegiate esports mirrors that of the early stages of college sports almost a century ago. Programs offer multiple esports titles ranging from Valorant and Rocket League to Mario Kart and Madden. The three main leagues are NECC, PlayFly, and NACE. Each league has varying membership fees, benefits, and game offerings. This is a problem directors face with the current state of esports. Most schools cannot afford the membership fees associated with all three leagues, so their directors must be picky when selecting which league best services, the needs of their program. 
NECC is the largest of the three leagues by player and offering size. According to NECC, 123 universities participated in Fall 2021, which provided approximately 3,000 students with opportunities to compete within their respective games (NECC ESPORTS, 2021). This number has since grown, as well as the selection of titles. When NECC first started, they offered Valorant, Rocket League, Rainbow Six Siege, Overwatch, and League of Legends. Four years after, in Fall 2024, NECC offered every game previously mentioned in addition to Counter-Strike and Super Smash Bros within the main membership fee. NECC also partnered with two single game leagues in College Cod and College Halo to bring competitive Call of Duty and competitive Halo underneath their management sphere. While these games are not included in their membership fee for $750, you can participate in these side leagues for a small fee. Another step NECC took was the introduction of single game tournaments that were put together by their interns. These tournaments added in seven additional titles that students could compete in. 
	As any organization grows, it is important to make sure the needs of your original members are met as well as meeting the needs of prospective members. One way to do this is by sending out a year end survey. Since their inauguration in year zero (2020-2021), NECC has provided its members with a survey to see what they need to improve on. 
Literature Review
	Organizations in many different industries provide year end surveys to customers in order to help them identify areas of operations that are falling behind. Currently there is limited data on this topic, as college esports is extremely new. Since college esports is so new, there is no actual history of AI use by leagues to determine the key indicators of what causes coaches to choose one league or the other. After all, directors and leagues share a similar relationship to a customer and a company. Because of this, I decided to investigate how AI is used in customer sentiment analysis as it provides the best alternative. Amazon identifies one of the best ways to use sentiment analysis is within market researching (Amazon). In the NECC case, using AI to analyze their year end surveys would provide them the opportunity to get an in depth understanding of the collegiate esports market. 
Knowing the desires of your target market provides a competitive advantage to the organization who utilizes these tools. NLP also allows for these organizations to take advantage of these insights through the actions of the organization. Johnny Wordsworth noted that if organizations were to notice a trend of reviews all mentioning the same issue, then it would provide the insight that users were experiencing similar issues. Having this knowledge allows the organization to fix the issues those users were experiencing, which reduces frustration in the user experience. On top of that, Wordsworth also notes that using natural language processing (NLP) is extremely efficient, which allows for more data to be sorted through, than through the means of humans (2024). NLP is able to accomplish this feat by removing stop words and by identifying common words. 
Nick Mishkin helps clarify what stop words are and how NLP effectively navigates around these words to help deliver clarity. “Stop words are common words that appear frequently and do not carry significant meaning” (2024). Mishkin is saying that words such as “the” “is” “a” “an” are all examples of stop words. These words provide little to the sentiment of a review, but rather help maintain a flow, which machines cannot understand. Here is an example “The casters are amazing and have great insight.” After removing the stop words, we are left with “casters amazing have great insight.” To us this sounds like broken English, but this is all a computer needs to identify which sentiment some words carry. In the example, if that review was left as 4 stars, then the machine would start to associate “casters”, “amazing”, “great”, and  “insight” as positive words. Let us add in another example, “The casters were awful and super bias towards the other team.” This review is general negative. If we only had the previous example as training data, then our AI would assume this review is generally positive because it recognizes casters as a positive word. This is why it is important to provide your AI with plenty of training data. 
In order to adequately train data, Thompson Stupak notes that the 10 times rule suggests that you should have at least 10 examples for each feature or predictor variable in your model (Stupak, 2024). Given the survey in this study had five outcomes, the ten times rule would suggest we need at minimum, 50 examples (10 for each category). In the provided dataset from NECC, we oversaw over 160 surveys from directors across the two years of data collected. The major downside is that majority did not fill in the reason for the review. They only applied a number. This unfortunately does not help the study as that means there is too little, which can lead to underfitting. 
Methodology
Being in collegiate esports myself, I have firsthand seen directors complaining about different aspects of each league on sources like X and in discord servers. The best remedy to a fragmented scene is to gather all groups together under one roof. Given that I have prior work experience with NECC, I was able to get in touch with Caleb who permitted me to use their older survey results in this study. In order for everyone to come together, one league must meet the needs of the majority of members. The data used in this study was provided by NECC and covered the year end surveys of 2021-2022 (2022) and more recently 2023-2024 (2024). Unfortunately, I was not able to get access to 2022–2023-year end survey. 
The initial steps taken for the data was to combine the records for 2020 and 2024. To do this I had to comb through and find the areas of the surveys that changed and which ones stayed the same. Between 2022 and 2024, NECC upgraded their tournament platform from using google sheets to using a website called leagueos. Upon the launch of the leagueos partnership, numerous directors struggled to get their programs onto the site. The initial onboarding phase was long and tedious. This was one of the questions that was added to the survey in 2024 that was not included in the 2022 survey. So, since I did not have sufficient data for that topic, I left it off of the report. 
The next step taken was to isolate the categories that were a frequent in conversations between directors on X. The categories selected were: Broadcasts, Game Selection, Divisional Structure and Membership Pricing. These were some of the most debated topics between directors and club presidents alike. Once isolated, I had to figure out how many of the responses were null. NECC required survey respondents to rate each category on a scale of one to five with one being the lowest. Survey respondents were then asked to elaborate if they chose to. This left a lot of null answer columns. The best example of this was of the 94 non null answers to membership pricing, only 31 respondents expressed their reasons for their answers. 
After removing the null answers, I then created histogram showing the overall sentiment of the category. I then cleaned the text by removing all stop words and punctuation. The next step was the remove the most common words. Given that I had a lower number of results to work from I chose to remove the five most common words. In the membership price example, “price” “teams” “think” “NECC” and “year” were removed. After removing the most common words, I tokenized the remaining words. The final step was to perform TF – IDF vectorization. These left us with words that help identify the sentiment of other reviews.

Results
 
The overall sentiment of broadcasts was relatively positive, but the AI pulled keywords. The most common feeling was that the broadcasts were high quality and the casters were great; however, they wished for more diversity of skill levels. Unlike that of PlayFly, NECC mainly stuck to their top two – three divisions for broadcast. For the negative reviews, directors often felt that the process to be on stream was very unorganized. This disorganization was caused by the lack of communication from the NECC broadcast coordinator. 
 
The overall sentiment of game selection as overwhelmingly positive similar to that of the broadcasts. Most directors put that they loved the current game selection for the core games as these make up the main interests in the collegiate esports’ world. The reason that this category did not get a perfect five was because most directors felt that NECC offered the most common competitive games; however, they lacked a couple of less common options that other leagues provided. These smaller titles included: Mario Kart, Madden, Fifa, and Smash. This has drastically changed since these forms were collected. NECC now offers smash as a core game and runs side tournaments featuring these other games noted in the reviews.
 
The divisional structure saw the most responses that had explanations for their rating. The results were mixed across the board, but the general census was that the structure was good; however, there were many exploits in the system that caused some divisions to be unfair. To fix this a couple directors suggested that more divisions be created. This actually was something that NECC incorporated this year expanding from four divisions to having seven in Rocket League, their most popular title.


 
The final category was membership pricing. This provided extremely positive results. Their $750 for a full year of unlimited games and teams proved to be a hit within the community as it allowed for clubs to do fund raisers to collect the entry fee. The unlimited teams also proved to be a hit, as clubs usually have multiple teams per game. During my time at Bowling Green State University, we had four Rocket League teams that competed. Some of the complaints were that the pricing was too steep for smaller clubs. These clubs felt that the price was not worth it as they were only able to field one team. To remedy this, NECC partnered with sponsors to help provide the membership fees for these smaller clubs. 


Conclusion
The NECC is committed to providing quality leagues and broadcasts all for an affordable price. The reason for the growth is due to the success of their leadership who have found a way to create a community that allows for competition between varsity programs and club teams alike. There were some limitations to the model chosen. The model was underfit due to the lack of data. While having about 100 ratings for each category, most only saw 30-40 directors giving reasons for the ratings. Given ample reasons, the AI would be able to pick out the most common phrases associated with the failures of the NECC, so that they would be able to correct those for future seasons. Another limitation with the data was that it was spread out over three years. Collegiate esports are a rapidly changing environment that can see drastic changes in only a years’ time. 
One suggestion I have for future implementations of this model is that it requires a relatively high number of responses to function. In 2024, the NECC had around 400 schools competing. In order to feed the AI correctly, almost half of the program leads would have to reply to the survey. Of the half that choose to reply, at least 30% would have to provide reasons for their results. It would be in the best interest of the AI to require reasons for the ratings even if the reason is “great quality.” This would help train the AI better to allow organizations to correct gripes that the community has, which over time will reduce the fragmentation of the collegiate esports industry. 
